---
title: "dattri: A Library for Efficient Data Attribution"
tags:
- "Data Attribution"
- "Open Source Library"
date: 2024-07-17
priority: -20240717
path: "research/dattri"
excerpt: "We developed a efficient library for data attribution, aiming to streamline the development of data attribution algorithms"
selected: false
cover: "./preview.png"
links:
#   - name: "GitHub"
#     url: "https://github.com/sleepymalc/Travel-the-Same-Path"
  # - name: "arXiv"
  #   url: "https://arxiv.org/abs/2404.11577"
authors:
  - name: "Junwei Deng*"
    url: "https://theaperdeng.github.io/"
  - name: "Ting-Wei Li*"
    url: "https://tingwl0122.github.io/"
  - name: "Shiyuan Zhang"
    url: "https://seanzh30.github.io/"
  - name: "Yijun Pan"
    # url:
  - name: "Hao Huang"
    # url:
  - name: "Xinhe Wang"
    # url:
  - name: "Pingbang Hu"
    url: "https://pbb.wtf"
  - name: "Xingjian Zhang"
    url: "https://sites.google.com/umich.edu/xingjian-zhang/"
  - name: Jiaqi Ma
    url: "https://jiaqima.github.io/"
---

## Brief Summary

<!-- How can we attribute the behaviors of machine learning models to their training data? While the classic *influence function*[^1] sheds light on the impact of individual samples, it often fails to capture the more complex and pronounced collective influence of a set of samples. To tackle this challenge, we study the Most Influential Subset Selection (MISS) problem, which aims to identify a subset of training samples with the greatest collective influence. We conduct a comprehensive analysis of the prevailing approaches in MISS, elucidating their strengths and weaknesses. Our findings reveal that influence-based greedy heuristics, a dominant class of algorithms in MISS, can provably fail even in linear regression. We delineate the failure modes, including the errors of influence function and the non-additive structure of the collective influence. Conversely, we demonstrate that an adaptive version of these heuristics which applies them iteratively, can effectively capture the interactions among samples and thus partially address the issues. Experiments on real-world datasets corroborate these theoretical findings, and further demonstrate that the merit of adaptivity can extend to more complex scenarios such as classification tasks and non-linear neural networks. We conclude our analysis by highlighting the inherent trade-off between performance and computational efficiency, and providing a range of discussions.

[^1]: <https://arxiv.org/abs/1703.04730> -->
